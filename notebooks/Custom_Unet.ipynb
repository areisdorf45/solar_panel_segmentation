{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4d7440-7721-4dda-b0c1-8853668b2b21",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08a505d-e185-4447-abb8-9d2fba6bba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, Activation, Concatenate\n",
    "from tensorflow.keras.metrics import BinaryIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87808c-45fb-4456-8d98-ea69ce4874e5",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a6e3f6-fbc9-4f10-871f-2901d39e8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561d085a-f136-4e27-b427-4460e158d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X = os.path.join(home,'raw_data/image_slices')\n",
    "path_y = os.path.join(home,'raw_data/mask_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1da0666-312e-4a2c-a6c7-91ee047f73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d000d156-83bc-4b49-981f-a9d5c0416363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split (path_X, path_y, split_ratio):\n",
    "    X_names = os.listdir(path_X)\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    train_X, val_X = X_path[:int(len(X_path)*split_ratio)], X_path[int(len(X_path)*split_ratio):]\n",
    "    train_y, val_y = y_path[:int(len(y_path)*split_ratio)], y_path[int(len(y_path)*split_ratio):]\n",
    "    return train_X, val_X, train_y, val_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dde256-6fc2-49cd-ba13-553180cbd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_val_split (path_X, path_y, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aeddb1e-9902-49bb-83ec-4df58ad75f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_matching_input_labels(X_names, y_names):\n",
    "    for x, y in zip(X_names, y_names):\n",
    "        if os.path.basename(x) != os.path.basename(y):\n",
    "            raise ValueError(f\"X and Y not matching: {x, y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1faf57c2-9e80-49b6-9436-3c8974bae7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8c04b9-c886-4898-ab22-d994e2f64593",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8f340c-d603-4f01-8156-30ef64535ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    image = tf.image.decode_png(image, channels = 3)\n",
    "    mask = tf.image.decode_png(mask, channels = 1) / 255 \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27bd5188-fe0a-4080-842a-0776ec69d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data (X_path, y_path, batch_size):\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.shuffle(buffer_size = len(X_path), seed = 10).map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8a4e9-99d8-4820-91f1-4d04524ae627",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dccd6a75-528c-45a1-8087-4a857e436584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 10:21:17.427015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:17.573086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:17.574919: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:17.579678: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-02 10:21:17.582503: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:17.584355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:17.586074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:19.071126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:19.073191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:19.074968: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-02 10:21:19.077610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = batch_data(train_X, train_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d8bf7-8b05-4618-86b7-c96eccefdf74",
   "metadata": {},
   "source": [
    "### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f4b3ee9-b134-407b-99de-59d59aa9a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = batch_data(val_X, val_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401aa3a9-a713-49f9-af9d-ba8b55679f42",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f57f275-a169-44c1-a577-49c135c93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X_TEST = os.path.join(home,'raw_data/TEST_slices/test_image_slices')\n",
    "path_y_TEST = os.path.join(home,'raw_data/TEST_slices/test_mask_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1264cea-bf4a-4570-a62b-cd67f54a34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data_test (path_X, path_y, batch_size):\n",
    "    X_names = os.listdir(path_X)\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08703db-88a9-47e4-a553-83ac4ea9b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_dataset = batch_data_test(path_X_TEST, path_y_TEST, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea696bf-c7b4-4e49-89ba-2d03c8669ced",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f50a6e10-5c32-449a-8231-9c62defaa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, (3,3), padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4ecf07b-46e6-4eb8-b81a-6d86db51c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters) #can be used as skip connection \n",
    "    p = MaxPooling2D((2,2))(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "001fd9da-03a9-4ca4-af47-9b239d406f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip_features, num_filters): #skip features are going to be the x returned from the encoder block\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f7e53c2-e63a-4bcf-b6d1-a80bd02f0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(targets, inputs, smooth=1e-6):\n",
    "    \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    \n",
    "    intersection = K.sum(targets * inputs)\n",
    "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df641753-57e6-4221-988d-44996beb2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_sum(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    o = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8ef0801-13bb-41b2-848c-3fd856183794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(img_height, img_width, channels):\n",
    "    \n",
    "    inputs = Input((img_height, img_width, channels))\n",
    "    inputs = Lambda(lambda x: x / 255)(inputs) #Normalize the pixels by dividing by 255\n",
    "\n",
    "    #Encoder - downscaling (creating features/filter)\n",
    "    skip1, pool1 = encoder_block(inputs, 16)\n",
    "    skip2, pool2 = encoder_block(pool1, 32) \n",
    "    skip3, pool3 = encoder_block(pool2, 64)\n",
    "    skip4, pool4 = encoder_block(pool3, 128) \n",
    "    \n",
    "    #Bottleneck or bridge between encoder and decoder\n",
    "    b1 = conv_block(pool4, 256)\n",
    "    \n",
    "    #Decoder - upscaling (reconstructing the image and giving it precise spatial location)\n",
    "    decoder1 = decoder_block(b1, skip4, 128)\n",
    "    decoder2 = decoder_block(decoder1, skip3, 64)\n",
    "    decoder3 = decoder_block(decoder2, skip2, 32)\n",
    "    decoder4 = decoder_block(decoder3, skip1, 16)\n",
    "    \n",
    "    #Output\n",
    "    outputs = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(decoder4)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    iou = BinaryIoU()\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=loss_sum, metrics=['accuracy', iou])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d0b5984-3721-44ca-8a08-ca8c95fe17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet(256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d25d69a8-86cd-4b1a-a3b9-526c9b770360",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '../tmp/simple_unet/loss_sum_trainingset'\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_loss', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "787df192-b4f3-46f6-b1c4-73c7fc9759cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#history = model.fit(train_dataset, validation_data=val_dataset, epochs = 500, callbacks=[es, checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdcd621f-e215-45a7-862b-ef4443725e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['val_binary_io_u'], label='validation set')\n",
    "# plt.plot(history.history['binary_io_u'], label='training set')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cfe6752-51ff-48de-b337-c60b99061b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = build_unet(256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "820374b6-df18-445d-8573-232c19b36fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f45db607d10>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.load_weights(checkpoint_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c3d61b5-df79-4c39-b6bd-037b1d27254d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-02 10:24:08.489435: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/565 [==============================] - 35s 47ms/step - loss: 0.2795 - accuracy: 0.9611 - binary_io_u_1: 0.8587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27950355410575867, 0.9610777497291565, 0.8586697578430176]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.evaluate(TEST_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f72ba7f-a542-455c-8c5d-1e2da5b5440b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 40  64  57]\n",
      "   [ 37  61  54]\n",
      "   [ 39  63  56]\n",
      "   ...\n",
      "   [ 40  59  57]\n",
      "   [ 45  64  63]\n",
      "   [ 40  62  60]]\n",
      "\n",
      "  [[ 43  65  57]\n",
      "   [ 44  67  59]\n",
      "   [ 47  69  62]\n",
      "   ...\n",
      "   [ 40  60  57]\n",
      "   [ 49  68  66]\n",
      "   [ 45  64  62]]\n",
      "\n",
      "  [[ 40  63  55]\n",
      "   [ 47  70  62]\n",
      "   [ 52  73  67]\n",
      "   ...\n",
      "   [ 52  70  66]\n",
      "   [ 52  71  68]\n",
      "   [ 48  67  64]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 77  95  77]\n",
      "   [ 86  99  83]\n",
      "   [ 88  99  87]\n",
      "   ...\n",
      "   [ 38  61  55]\n",
      "   [ 43  69  61]\n",
      "   [ 43  68  59]]\n",
      "\n",
      "  [[ 81 101  87]\n",
      "   [ 95 113  98]\n",
      "   [ 74  93  80]\n",
      "   ...\n",
      "   [ 41  62  58]\n",
      "   [ 37  64  56]\n",
      "   [ 42  67  58]]\n",
      "\n",
      "  [[ 64  88  74]\n",
      "   [ 76  99  85]\n",
      "   [ 60  83  69]\n",
      "   ...\n",
      "   [ 45  65  62]\n",
      "   [ 40  63  56]\n",
      "   [ 41  65  56]]]\n",
      "\n",
      "\n",
      " [[[195 199 202]\n",
      "   [193 198 201]\n",
      "   [193 198 201]\n",
      "   ...\n",
      "   [127 155 132]\n",
      "   [126 154 131]\n",
      "   [138 166 143]]\n",
      "\n",
      "  [[187 192 195]\n",
      "   [187 192 195]\n",
      "   [188 193 196]\n",
      "   ...\n",
      "   [132 160 137]\n",
      "   [128 156 133]\n",
      "   [140 168 145]]\n",
      "\n",
      "  [[185 190 193]\n",
      "   [185 190 193]\n",
      "   [186 191 194]\n",
      "   ...\n",
      "   [135 163 138]\n",
      "   [128 156 131]\n",
      "   [139 167 142]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[101 134 113]\n",
      "   [105 138 117]\n",
      "   [106 140 116]\n",
      "   ...\n",
      "   [113 141 126]\n",
      "   [123 152 134]\n",
      "   [119 148 128]]\n",
      "\n",
      "  [[103 137 113]\n",
      "   [105 139 115]\n",
      "   [107 141 117]\n",
      "   ...\n",
      "   [101 129 114]\n",
      "   [116 145 127]\n",
      "   [116 145 127]]\n",
      "\n",
      "  [[107 141 117]\n",
      "   [104 138 114]\n",
      "   [101 135 111]\n",
      "   ...\n",
      "   [105 133 118]\n",
      "   [122 151 133]\n",
      "   [100 129 111]]]\n",
      "\n",
      "\n",
      " [[[ 96 112  79]\n",
      "   [ 98 114  81]\n",
      "   [ 98 115  81]\n",
      "   ...\n",
      "   [ 81  95  60]\n",
      "   [ 91 106  69]\n",
      "   [104 121  86]]\n",
      "\n",
      "  [[ 93 111  78]\n",
      "   [ 97 113  80]\n",
      "   [100 113  81]\n",
      "   ...\n",
      "   [ 82  96  61]\n",
      "   [100 116  82]\n",
      "   [116 132 102]]\n",
      "\n",
      "  [[ 92 111  77]\n",
      "   [ 96 112  80]\n",
      "   [ 98 113  80]\n",
      "   ...\n",
      "   [ 87 105  69]\n",
      "   [107 122  93]\n",
      "   [121 134 109]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 94  80  49]\n",
      "   [116 108  84]\n",
      "   [118 105  81]\n",
      "   ...\n",
      "   [145 140 119]\n",
      "   [142 133 114]\n",
      "   [142 138 119]]\n",
      "\n",
      "  [[ 83  78  51]\n",
      "   [118 110  90]\n",
      "   [118 111  86]\n",
      "   ...\n",
      "   [150 145 122]\n",
      "   [142 129 108]\n",
      "   [142 120 101]]\n",
      "\n",
      "  [[ 97  94  68]\n",
      "   [113 113  89]\n",
      "   [113 112  86]\n",
      "   ...\n",
      "   [147 139 115]\n",
      "   [143 124 104]\n",
      "   [130 103  80]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 70  69  48]\n",
      "   [ 52  50  35]\n",
      "   [ 52  48  35]\n",
      "   ...\n",
      "   [155 151 128]\n",
      "   [133 131 110]\n",
      "   [167 160 139]]\n",
      "\n",
      "  [[ 63  61  41]\n",
      "   [ 67  63  47]\n",
      "   [ 44  41  33]\n",
      "   ...\n",
      "   [133 134 108]\n",
      "   [161 158 139]\n",
      "   [164 161 146]]\n",
      "\n",
      "  [[ 59  58  38]\n",
      "   [ 53  54  37]\n",
      "   [ 69  72  49]\n",
      "   ...\n",
      "   [143 140 118]\n",
      "   [141 136 111]\n",
      "   [150 150 128]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 30  35  37]\n",
      "   [ 26  30  32]\n",
      "   [ 25  28  31]\n",
      "   ...\n",
      "   [ 40  38  35]\n",
      "   [ 48  52  43]\n",
      "   [ 47  43  37]]\n",
      "\n",
      "  [[ 31  35  36]\n",
      "   [ 28  31  32]\n",
      "   [ 29  31  33]\n",
      "   ...\n",
      "   [ 50  50  43]\n",
      "   [ 47  45  39]\n",
      "   [ 44  50  44]]\n",
      "\n",
      "  [[ 31  35  36]\n",
      "   [ 27  30  31]\n",
      "   [ 26  29  30]\n",
      "   ...\n",
      "   [ 47  50  43]\n",
      "   [ 44  44  40]\n",
      "   [ 44  43  36]]]\n",
      "\n",
      "\n",
      " [[[120 117 124]\n",
      "   [126 123 132]\n",
      "   [123 119 133]\n",
      "   ...\n",
      "   [111 146 124]\n",
      "   [110 145 123]\n",
      "   [109 144 122]]\n",
      "\n",
      "  [[116 113 122]\n",
      "   [121 118 129]\n",
      "   [121 117 131]\n",
      "   ...\n",
      "   [112 147 125]\n",
      "   [111 146 124]\n",
      "   [109 144 122]]\n",
      "\n",
      "  [[111 110 118]\n",
      "   [117 115 126]\n",
      "   [123 119 133]\n",
      "   ...\n",
      "   [111 149 126]\n",
      "   [112 147 125]\n",
      "   [109 144 122]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 98 131 112]\n",
      "   [101 134 115]\n",
      "   [103 136 117]\n",
      "   ...\n",
      "   [167 164 145]\n",
      "   [167 164 145]\n",
      "   [166 163 144]]\n",
      "\n",
      "  [[104 137 118]\n",
      "   [102 135 116]\n",
      "   [100 133 114]\n",
      "   ...\n",
      "   [186 183 164]\n",
      "   [197 194 175]\n",
      "   [185 182 163]]\n",
      "\n",
      "  [[104 137 118]\n",
      "   [ 97 130 111]\n",
      "   [ 94 127 108]\n",
      "   ...\n",
      "   [200 197 178]\n",
      "   [188 185 166]\n",
      "   [181 178 159]]]\n",
      "\n",
      "\n",
      " [[[ 84  87  78]\n",
      "   [ 78  81  72]\n",
      "   [ 70  73  64]\n",
      "   ...\n",
      "   [ 61  89  75]\n",
      "   [ 61  89  75]\n",
      "   [ 61  89  75]]\n",
      "\n",
      "  [[ 76  77  69]\n",
      "   [ 65  66  58]\n",
      "   [ 61  62  54]\n",
      "   ...\n",
      "   [ 61  89  75]\n",
      "   [ 61  89  75]\n",
      "   [ 61  89  75]]\n",
      "\n",
      "  [[ 48  49  41]\n",
      "   [ 48  49  41]\n",
      "   [ 64  65  57]\n",
      "   ...\n",
      "   [ 61  89  75]\n",
      "   [ 61  89  75]\n",
      "   [ 61  89  75]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 68  79  62]\n",
      "   [ 71  82  65]\n",
      "   [ 69  80  63]\n",
      "   ...\n",
      "   [ 75  95  84]\n",
      "   [ 75  95  84]\n",
      "   [ 75  95  84]]\n",
      "\n",
      "  [[ 44  55  38]\n",
      "   [ 51  62  45]\n",
      "   [ 51  62  45]\n",
      "   ...\n",
      "   [ 75  95  84]\n",
      "   [ 75  95  84]\n",
      "   [ 75  95  84]]\n",
      "\n",
      "  [[ 50  61  44]\n",
      "   [ 49  60  43]\n",
      "   [ 51  62  45]\n",
      "   ...\n",
      "   [ 75  95  84]\n",
      "   [ 75  95  84]\n",
      "   [ 75  95  84]]]], shape=(16, 256, 256, 3), dtype=uint8) tf.Tensor(\n",
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]\n",
      "\n",
      "  [[1.]\n",
      "   [1.]\n",
      "   [1.]\n",
      "   ...\n",
      "   [1.]\n",
      "   [1.]\n",
      "   [1.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]], shape=(16, 256, 256, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for x, y in TEST_dataset:\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e11f5933-02f7-4011-b39d-8d950be8091e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model.predict(x)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
