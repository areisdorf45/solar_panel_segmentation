{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4d7440-7721-4dda-b0c1-8853668b2b21",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d08a505d-e185-4447-abb8-9d2fba6bba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate, Activation, Concatenate\n",
    "from tensorflow.keras.metrics import IoU, BinaryIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import cv2 as cv\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87808c-45fb-4456-8d98-ea69ce4874e5",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a6e3f6-fbc9-4f10-871f-2901d39e8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561d085a-f136-4e27-b427-4460e158d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X = os.path.join(home,'raw_data/image_slices')\n",
    "path_y = os.path.join(home,'raw_data/mask_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdb4e15c-62e9-4c3a-83ef-1b30dc286f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_small_X = os.path.join(home,'raw_data/small_dataset/sample_images')\n",
    "# path_small_y = os.path.join(home,'raw_data/small_dataset/sample_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1da0666-312e-4a2c-a6c7-91ee047f73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d000d156-83bc-4b49-981f-a9d5c0416363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split (path_X, path_y, split_ratio):\n",
    "    X_names = os.listdir(path_X)\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    train_X, val_X = X_path[:int(len(X_path)*split_ratio)], X_path[int(len(X_path)*split_ratio):]\n",
    "    train_y, val_y = y_path[:int(len(y_path)*split_ratio)], y_path[int(len(y_path)*split_ratio):]\n",
    "    return train_X, val_X, train_y, val_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "323489f2-c09a-45c1-863a-656e705ff475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X, val_X, train_y, val_y = train_val_split (path_small_X, path_small_y, split_ratio) #small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16dde256-6fc2-49cd-ba13-553180cbd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_val_split (path_X, path_y, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aeddb1e-9902-49bb-83ec-4df58ad75f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_matching_input_labels(X_names, y_names):\n",
    "    for x, y in zip(X_names, y_names):\n",
    "        if os.path.basename(x) != os.path.basename(y):\n",
    "            raise ValueError(f\"X and Y not matching: {x, y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1faf57c2-9e80-49b6-9436-3c8974bae7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a8c04b9-c886-4898-ab22-d994e2f64593",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed8f340c-d603-4f01-8156-30ef64535ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    image = tf.image.decode_png(image, channels = 3)\n",
    "    mask = tf.image.decode_png(mask, channels = 1) / 255 \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27bd5188-fe0a-4080-842a-0776ec69d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data (X_path, y_path, batch_size):\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.shuffle(buffer_size = len(X_path), seed = 10).map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8a4e9-99d8-4820-91f1-4d04524ae627",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dccd6a75-528c-45a1-8087-4a857e436584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 16:38:30.905984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:30.917380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:30.919191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:30.922084: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-04 16:38:30.923136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:30.925041: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:30.926841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:31.587119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:31.589227: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:31.590942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-04 16:38:31.592684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = batch_data(train_X, train_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d8bf7-8b05-4618-86b7-c96eccefdf74",
   "metadata": {},
   "source": [
    "### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4b3ee9-b134-407b-99de-59d59aa9a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = batch_data(val_X, val_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401aa3a9-a713-49f9-af9d-ba8b55679f42",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f57f275-a169-44c1-a577-49c135c93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X_TEST = os.path.join(home,'raw_data/TEST_slices/test_image_slices')\n",
    "path_y_TEST = os.path.join(home,'raw_data/TEST_slices/test_mask_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1264cea-bf4a-4570-a62b-cd67f54a34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data_test (path_X, path_y, batch_size):\n",
    "    X_names = os.listdir(path_X)\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a08703db-88a9-47e4-a553-83ac4ea9b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_dataset = batch_data_test(path_X_TEST, path_y_TEST, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea696bf-c7b4-4e49-89ba-2d03c8669ced",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97da325-0098-48a6-a92f-21374960c8ba",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78b068c6-5455-4461-b85b-1bbec9b83cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_relu(inputs):\n",
    "    x = BatchNormalization()(inputs)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1285bb44-2ee5-4632-9342-063a4843b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(inputs, num_filters, strides=1):\n",
    "    #Convolutional Layer\n",
    "    x = batchnorm_relu(inputs)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", strides=strides)(x)\n",
    "    x = batchnorm_relu(x)\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\", strides=1)(x)\n",
    "    \n",
    "    #Shortcut\n",
    "    shortcut = Conv2D(num_filters, (1,1), padding='same', strides=strides)(inputs)\n",
    "               \n",
    "    #Addition ofthe convolutional layer and shortcut\n",
    "    x = x + shortcut\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92015546-7ceb-4414-8726-12c487ef66ec",
   "metadata": {},
   "source": [
    "**UpSampling2D** is just a *simple scaling* up of the image by using nearest neighbour or bilinear upsampling, so nothing smart. Advantage is it's cheap.\n",
    "\n",
    "**Conv2DTranspose** is a *convolution operation whose kernel is learnt* (just like normal conv2d operation) while training your model. Using Conv2DTranspose will also upsample its input but the key difference is the model should learn what is the best upsampling for the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1834a4e5-2cbf-4e91-b573-615fbdb1ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    # = UpSampling2D((2, 2))(inputs)\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = residual_block(x, num_filters, strides=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f7e53c2-e63a-4bcf-b6d1-a80bd02f0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(targets, inputs, smooth=1e-6):\n",
    "    \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    \n",
    "    intersection = K.sum(targets * inputs)\n",
    "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df641753-57e6-4221-988d-44996beb2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_sum(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    o = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8ef0801-13bb-41b2-848c-3fd856183794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resunet(img_height, img_width, channels):\n",
    "    \n",
    "    #Inputs\n",
    "    inputs = Input((img_height, img_width, channels))\n",
    "    inputs = Lambda(lambda x: x / 255)(inputs) #Normalize the pixels by dividing by 255\n",
    "    \n",
    "    #Encoder 1\n",
    "    x = Conv2D(64, (3,3), padding='same', strides=1)(inputs)\n",
    "    x = batchnorm_relu(x)\n",
    "    x = Conv2D(64, (3,3), padding='same', strides=1)(x)\n",
    "    shortcut = Conv2D(64, (1,1), padding='same', strides=1)(inputs) #shortcut using the identity matrix\n",
    "    skip1 = x + shortcut #this referes to the skip connection for the decoder\n",
    "    \n",
    "    #Encoder 2 and 3\n",
    "    skip2 = residual_block(skip1, 128, strides=2)\n",
    "    skip3 = residual_block(skip2, 256, strides=2)\n",
    "    \n",
    "    #Bridge/Bottleneck\n",
    "    b = residual_block(skip3, 512, strides=2)\n",
    "    \n",
    "    #Decoder 1, 2, 3\n",
    "    x = decoder_block(b, skip3, 256)\n",
    "    x = decoder_block(x, skip2, 128)\n",
    "    x = decoder_block(x, skip1, 64)\n",
    "    \n",
    "    #Classifier\n",
    "    outputs= Conv2D(1, (1,1), padding='same', activation='sigmoid')(x)\n",
    "    \n",
    "    #Model\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    #Metrics\n",
    "    iou = BinaryIoU()\n",
    "    \n",
    "    #Compile\n",
    "    model.compile(optimizer='adam', loss=loss_sum, metrics=['accuracy', iou])\n",
    "    \n",
    "    model.summary()\n",
    "       \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d0b5984-3721-44ca-8a08-ca8c95fe17de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[1][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[1][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[1][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 64  256         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 256, 256, 64  0          ['conv2d_1[1][0]',               \n",
      " da)                            )                                 'conv2d_2[1][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['tf.__operators__.add[1][0]']   \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  73856       ['activation_1[1][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[1][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[1][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[1][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 12  8320        ['tf.__operators__.add[1][0]']   \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 128, 128, 12  0          ['conv2d_4[1][0]',               \n",
      " mbda)                          8)                                'conv2d_5[1][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['tf.__operators__.add_1[1][0]'] \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[1][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 256)  295168      ['activation_3[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_6[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 64, 64, 256)  33024       ['tf.__operators__.add_1[1][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 64, 64, 256)  0          ['conv2d_7[1][0]',               \n",
      " mbda)                                                            'conv2d_8[1][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['tf.__operators__.add_2[1][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 512)  1180160     ['activation_5[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_9[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_6[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 32, 512)  131584      ['tf.__operators__.add_2[1][0]'] \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 32, 32, 512)  0          ['conv2d_10[1][0]',              \n",
      " mbda)                                                            'conv2d_11[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 64, 256)  524544     ['tf.__operators__.add_3[1][0]'] \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 512)  0           ['conv2d_transpose[1][0]',       \n",
      "                                                                  'tf.__operators__.add_2[1][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 512)  2048       ['concatenate[1][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_7[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1179904     ['activation_7[1][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_12[1][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_8[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_8[1][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 256)  131328      ['concatenate[1][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TFOpLa  (None, 64, 64, 256)  0          ['conv2d_13[1][0]',              \n",
      " mbda)                                                            'conv2d_14[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 12  131200     ['tf.__operators__.add_4[1][0]'] \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_1[1][0]',     \n",
      "                                6)                                'tf.__operators__.add_1[1][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 128, 128, 25  1024       ['concatenate_1[1][0]']          \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_9[1][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 128, 12  295040      ['activation_9[1][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[1][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_10[1][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 12  147584      ['activation_10[1][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 12  32896       ['concatenate_1[1][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TFOpLa  (None, 128, 128, 12  0          ['conv2d_16[1][0]',              \n",
      " mbda)                          8)                                'conv2d_17[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 64  32832      ['tf.__operators__.add_5[1][0]'] \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_2[1][0]',     \n",
      "                                8)                                'tf.__operators__.add[1][0]']   \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 256, 256, 12  512        ['concatenate_2[1][0]']          \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_11[1][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 64  73792       ['activation_11[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 256, 256, 64  256        ['conv2d_18[1][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_12[1][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 256, 256, 64  36928       ['activation_12[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 256, 64  8256        ['concatenate_2[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TFOpLa  (None, 256, 256, 64  0          ['conv2d_19[1][0]',              \n",
      " mbda)                          )                                 'conv2d_20[1][0]']              \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 256, 256, 1)  65          ['tf.__operators__.add_6[1][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,054,017\n",
      "Trainable params: 8,048,513\n",
      "Non-trainable params: 5,504\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_resunet(256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d25d69a8-86cd-4b1a-a3b9-526c9b770360",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '../tmp/resnet/version1'\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_loss', restore_best_weights=True)\n",
    "\n",
    "#log data for tensorboard visualization\n",
    "logs_dir = \"../logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir = logs_dir , histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a6f6d-0299-4bc4-968a-1c5f0ebf1c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-04 16:41:41.714526: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3845/3845 [==============================] - 3747s 975ms/step - loss: 0.4900 - accuracy: 0.9282 - binary_io_u: 0.7735 - val_loss: 0.5352 - val_accuracy: 0.9236 - val_binary_io_u: 0.7501\n",
      "Epoch 3/100\n",
      "3845/3845 [==============================] - 3730s 970ms/step - loss: 0.2575 - accuracy: 0.9622 - binary_io_u: 0.8726 - val_loss: 0.3143 - val_accuracy: 0.9539 - val_binary_io_u: 0.8457\n",
      "Epoch 14/100\n",
      "3845/3845 [==============================] - 3723s 968ms/step - loss: 0.2511 - accuracy: 0.9632 - binary_io_u: 0.8757 - val_loss: 0.3103 - val_accuracy: 0.9539 - val_binary_io_u: 0.8484\n",
      "Epoch 15/100\n",
      "3845/3845 [==============================] - 3731s 970ms/step - loss: 0.2426 - accuracy: 0.9645 - binary_io_u: 0.8799 - val_loss: 0.3084 - val_accuracy: 0.9549 - val_binary_io_u: 0.8488\n",
      "Epoch 16/100\n",
      "3845/3845 [==============================] - 3729s 970ms/step - loss: 0.2356 - accuracy: 0.9655 - binary_io_u: 0.8829 - val_loss: 0.3094 - val_accuracy: 0.9551 - val_binary_io_u: 0.8473\n",
      "Epoch 17/100\n",
      "3222/3845 [========================>.....] - ETA: 9:44 - loss: 0.2283 - accuracy: 0.9667 - binary_io_u: 0.8864"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs = 100, callbacks=[es, checkpoint, tb_callback], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d529ae0e-230c-49dc-a0ac-9f2a3282b212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs: 31\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of epochs:\", len(history.history['val_binary_io_u'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0812e9a-f8ae-45b9-96c0-5d1be11a3aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.2913\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation loss:\", round(np.min(history.history['val_loss']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9024e0bd-7ed5-4211-beeb-60087c877f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.9573\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation accuracy:\", round(np.max(history.history['val_accuracy']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a9987208-bc0f-48a1-ab07-605c246cee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation iou: 0.8564\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation iou:\", round(np.max(history.history['val_binary_io_u']),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dff32a5d-29dc-4a56-9ba0-53af1fb29039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565/565 [==============================] - 162s 286ms/step - loss: 0.3048 - accuracy: 0.9574 - binary_io_u: 0.8477\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3048243820667267, 0.9573831558227539, 0.8477343916893005]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(TEST_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "11dae724-72ad-4567-b98b-eb2fead6c460",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('../tmp/resnet/version1')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
