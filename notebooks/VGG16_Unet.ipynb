{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4d7440-7721-4dda-b0c1-8853668b2b21",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08a505d-e185-4447-abb8-9d2fba6bba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate, Activation, Concatenate\n",
    "from tensorflow.keras.metrics import IoU, BinaryIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import cv2 as cv\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87808c-45fb-4456-8d98-ea69ce4874e5",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a6e3f6-fbc9-4f10-871f-2901d39e8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561d085a-f136-4e27-b427-4460e158d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path for entire dataset\n",
    "\n",
    "#path_X = os.path.join(home,'raw_data/image_slices')\n",
    "#path_y = os.path.join(home,'raw_data/mask_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4eb06733",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13435/3834430818.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_small_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'raw_data/small_dataset/sample_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpath_small_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'raw_data/small_dataset/sample_masks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "#Path for subset of dataset\n",
    "\n",
    "path_small_X = os.path.join(home,'raw_data/small_dataset/sample_images')\n",
    "path_small_y = os.path.join(home,'raw_data/small_dataset/sample_masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1da0666-312e-4a2c-a6c7-91ee047f73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d000d156-83bc-4b49-981f-a9d5c0416363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split (path_X, path_y, split_ratio):\n",
    "    X_names = os.listdir(path_X)\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    train_X, val_X = X_path[:int(len(X_path)*split_ratio)], X_path[int(len(X_path)*split_ratio):]\n",
    "    train_y, val_y = y_path[:int(len(y_path)*split_ratio)], y_path[int(len(y_path)*split_ratio):]\n",
    "    return train_X, val_X, train_y, val_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91edab41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small Dataset\n",
    "train_X, val_X, train_y, val_y = train_val_split (path_small_X, path_small_y, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dde256-6fc2-49cd-ba13-553180cbd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entire Dataset\n",
    "# train_X, val_X, train_y, val_y = train_val_split (path_X, path_y, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aeddb1e-9902-49bb-83ec-4df58ad75f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_matching_input_labels(X_names, y_names):\n",
    "    for x, y in zip(X_names, y_names):\n",
    "        if os.path.basename(x) != os.path.basename(y):\n",
    "            raise ValueError(f\"X and Y not matching: {x, y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1faf57c2-9e80-49b6-9436-3c8974bae7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8c04b9-c886-4898-ab22-d994e2f64593",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8f340c-d603-4f01-8156-30ef64535ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    image = tf.image.decode_png(image, channels = 3)\n",
    "    mask = tf.image.decode_png(mask, channels = 1) / 255 \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27bd5188-fe0a-4080-842a-0776ec69d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data (X_path, y_path, batch_size):\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.shuffle(buffer_size = len(X_path), seed = 10).map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8a4e9-99d8-4820-91f1-4d04524ae627",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dccd6a75-528c-45a1-8087-4a857e436584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 13:32:17.444137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.581318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.583166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.587356: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 13:32:17.589774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.591595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.593294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:19.040736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:19.042766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:19.044498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:19.047631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = batch_data(train_X, train_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d8bf7-8b05-4618-86b7-c96eccefdf74",
   "metadata": {},
   "source": [
    "### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f4b3ee9-b134-407b-99de-59d59aa9a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = batch_data(val_X, val_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401aa3a9-a713-49f9-af9d-ba8b55679f42",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f57f275-a169-44c1-a577-49c135c93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_X_TEST = os.path.join(home,'raw_data/TEST_slices/test_image_slices')\n",
    "# path_y_TEST = os.path.join(home,'raw_data/TEST_slices/test_mask_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1264cea-bf4a-4570-a62b-cd67f54a34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data_test (path_X, path_y, batch_size):\n",
    "    X_names = os.listdir(path_X)\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08703db-88a9-47e4-a553-83ac4ea9b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST_dataset = batch_data_test(path_X_TEST, path_y_TEST, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea696bf-c7b4-4e49-89ba-2d03c8669ced",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Transfer Learning Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ec7d74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f50a6e10-5c32-449a-8231-9c62defaa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, (3,3), padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "001fd9da-03a9-4ca4-af47-9b239d406f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip_features, num_filters): #skip features are going to be the x returned from the encoder block\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2988ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vgg16_unet(img_height, img_width, channels):\n",
    "    inputs = Input((img_height, img_width, channels))\n",
    "    \n",
    "    vgg16= VGG16(include_top=False, weights='imagenet', input_tensor=inputs, )\n",
    "    \n",
    "    #Encoder\n",
    "    skip1 = vgg16.get_layer(\"block1_conv2\").output #shape 256, filters 64\n",
    "    skip2 = vgg16.get_layer(\"block2_conv2\").output #shape 128, filters 128\n",
    "    skip3 = vgg16.get_layer(\"block3_conv3\").output #shape 64, filters 256\n",
    "    skip4 = vgg16.get_layer(\"block4_conv3\").output #shape 32, filters 512\n",
    "        \n",
    "    #Bottleneck/Bridge ofthe Unet\n",
    "    b1 = vgg16.get_layer(\"block5_conv3\").output #shape 16, filters 512\n",
    "    \n",
    "    #Decoder\n",
    "    decoder1 = decoder_block(b1, skip4, 512)\n",
    "    decoder2 = decoder_block(decoder1, skip3, 256)\n",
    "    decoder3 = decoder_block(decoder2, skip2, 128)\n",
    "    decoder4 = decoder_block(decoder3, skip1, 64)\n",
    "    \n",
    "    #Output\n",
    "    outputs = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(decoder4)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    iou = BinaryIoU()\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=loss_sum, metrics=['accuracy', iou], name='VGG16_Unet')\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f7e53c2-e63a-4bcf-b6d1-a80bd02f0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(targets, inputs, smooth=1e-6):\n",
    "    \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    \n",
    "    intersection = K.sum(targets * inputs)\n",
    "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df641753-57e6-4221-988d-44996beb2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_sum(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    o = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d0b5984-3721-44ca-8a08-ca8c95fe17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_vgg16_unet(256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d25d69a8-86cd-4b1a-a3b9-526c9b770360",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '../tmp/vgg_unet/version1'\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_loss', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787df192-b4f3-46f6-b1c4-73c7fc9759cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 13:32:24.247942: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 523/3845 [===>..........................] - ETA: 8:36 - loss: 0.7240 - accuracy: 0.8867 - binary_io_u: 0.6829"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs = 500, callbacks=[es, checkpoint], verbose=1)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
