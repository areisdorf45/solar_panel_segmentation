{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276174f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:56:01.816959: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-01 15:56:01.817007: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import pathlib\n",
    "from tensorflow.keras import Input\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.metrics import MeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cb11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deviding data by batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "468e2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X = '/home/lewagon/code/Dponomareva/test/data/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "112d5363",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_y = '/home/lewagon/code/Dponomareva/test/data/Target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "332f629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f6b234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split (path_X, path_y, split_ratio):\n",
    "    X_names = os.listdir(path_X)\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    train_X, val_X = X_path[:int(len(X_path)*split_ratio)], X_path[int(len(X_path)*split_ratio):]\n",
    "    train_y, val_y = y_path[:int(len(y_path)*split_ratio)], y_path[int(len(y_path)*split_ratio):]\n",
    "    return train_X, val_X, train_y, val_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e398d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_val_split (path_X, path_y, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "892a9024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_matching_input_labels(X_names, y_names):\n",
    "    for x, y in zip(X_names, y_names):\n",
    "        if os.path.basename(x) != os.path.basename(y):\n",
    "            raise ValueError(f\"X and Y not matching: {x, y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7c32ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc5fcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f50cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2059572b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    image = tf.image.decode_png(image, channels = 3)\n",
    "    mask = tf.image.decode_png(mask, channels = 1)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd77f2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data (path_X, path_y, batch_size):\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((path_X, path_y))\n",
    "    return ds_train.map(process_path).batch(batch_size)\n",
    "    #return ds_train.shuffle(buffer_size = len(path_X), seed = 10).map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b8256f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_sum(y_true, y_pred):\n",
    "    def dice_loss(targets, inputs, smooth=1e-6):\n",
    "    #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "    \n",
    "        intersection = K.sum(targets * inputs)\n",
    "        dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "        return 1 - dice\n",
    "\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    #y_pred = tf.cast(y_pred, tf.float32)\n",
    "    o = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ef58e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(img_height, img_width, channels):\n",
    "\n",
    "    #Input\n",
    "    inputs = Input((img_height, img_width, channels))\n",
    "    inputs = Lambda(lambda x: x / 255)(inputs) #Normalize the pixels by dividing by 255\n",
    "\n",
    "    #Encoder where we are extracting the features\n",
    "    convolution1 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "    convolution1 = BatchNormalization()(convolution1) #other option is to do dropout by batch is faster \n",
    "    convolution1 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(convolution1)\n",
    "    pooling1 = MaxPooling2D((2, 2))(convolution1)\n",
    "      \n",
    "    convolution1 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\n",
    "    convolution1 = BatchNormalization()(convolution1) \n",
    "    convolution1 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(convolution1)\n",
    "    pooling1 = MaxPooling2D((2, 2))(convolution1)\n",
    "    \n",
    "    convolution2 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(pooling1)\n",
    "    convolution2 = BatchNormalization()(convolution2)\n",
    "    convolution2 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(convolution2)\n",
    "    pooling2 = MaxPooling2D((2, 2))(convolution2)\n",
    "     \n",
    "    convolution3 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(pooling2)\n",
    "    convolution3 = BatchNormalization()(convolution3)\n",
    "    convolution3 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(convolution3)\n",
    "    pooling3 = MaxPooling2D((2, 2))(convolution3)\n",
    "     \n",
    "    convolution4 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(pooling3)\n",
    "    convolution4 = BatchNormalization()(convolution4)\n",
    "    convolution4 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(convolution4)\n",
    "    pooling4 = MaxPooling2D(pool_size=(2, 2))(convolution4)\n",
    "\n",
    "    #Bottleneck at the base of the U-net \n",
    "    convolution5 = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same')(pooling4)\n",
    "    convolution5 = BatchNormalization()(convolution5)\n",
    "    convolution5 = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same')(convolution5)\n",
    "    \n",
    "    #Decoder where we are indicating to the model the precise location of the features \n",
    "    transconv6 = Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), padding='same')(convolution5)\n",
    "    transconv6 = concatenate([transconv6, convolution4])\n",
    "    convolution6 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(transconv6)\n",
    "    convolution6 = BatchNormalization()(convolution6)\n",
    "    convolution6 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(convolution6)\n",
    "     \n",
    "    transconv7 = Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding='same')(convolution6)\n",
    "    transconv7 = concatenate([transconv7, convolution3])\n",
    "    convolution7 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(transconv7)\n",
    "    convolution7 = BatchNormalization()(convolution7)\n",
    "    convolution7 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(convolution7)\n",
    "     \n",
    "    transconv8 = Conv2DTranspose(32, kernel_size=(2, 2), strides=(2, 2), padding='same')(convolution7)\n",
    "    transconv8 = concatenate([transconv8, convolution2])\n",
    "    convolution8 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(transconv8)\n",
    "    convolution8 = BatchNormalization()(convolution8)\n",
    "    convolution8 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(convolution8)\n",
    "     \n",
    "    transconv9 = Conv2DTranspose(16, kernel_size=(2, 2), strides=(2, 2), padding='same')(convolution8)\n",
    "    transconv9 = concatenate([transconv9, convolution1], axis=3)\n",
    "    convolution9 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(transconv9)\n",
    "    convolution9 = BatchNormalization()(convolution9)\n",
    "    convolution9 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(convolution9)\n",
    "     \n",
    "    outputs = Conv2D(1, kernel_size=(1, 1), activation='sigmoid')(convolution9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    jaccard = MeanIoU(2)\n",
    "    \n",
    "    #loss options include: binary_crossentropy, IoU Loss (Jaccard Index), dice loss\n",
    "    model.compile(optimizer='adam', loss=loss_sum) \n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3377c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75aeafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0c6be3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdaa3458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 15:56:04.678192: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-01 15:56:04.678273: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-01 15:56:04.678307: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (SLB-G9SSST2): /proc/driver/nvidia/version does not exist\n",
      "2022-12-01 15:56:04.678541: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 16  448         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 256, 16  64         ['conv2d_2[1][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 256, 16  2320        ['batch_normalization_1[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 16  0          ['conv2d_3[1][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 32  4640        ['max_pooling2d_1[1][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 128, 32  128        ['conv2d_4[1][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 32  9248        ['batch_normalization_2[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)  0           ['conv2d_5[1][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 64)   18496       ['max_pooling2d_2[1][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_6[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 64)   36928       ['batch_normalization_3[1][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)  0           ['conv2d_7[1][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 32, 128)  73856       ['max_pooling2d_3[1][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_8[1][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 128)  147584      ['batch_normalization_4[1][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0          ['conv2d_9[1][0]']               \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 16, 16, 256)  295168      ['max_pooling2d_4[1][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 16, 256)  1024       ['conv2d_10[1][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 256)  590080      ['batch_normalization_5[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 128)  131200     ['conv2d_11[1][0]']              \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 256)  0           ['conv2d_transpose[1][0]',       \n",
      "                                                                  'conv2d_9[1][0]']               \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 32, 32, 128)  295040      ['concatenate[1][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 128)  512        ['conv2d_12[1][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 32, 32, 128)  147584      ['batch_normalization_6[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 64)  32832       ['conv2d_13[1][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 64, 128)  0           ['conv2d_transpose_1[1][0]',     \n",
      "                                                                  'conv2d_7[1][0]']               \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 64, 64, 64)   73792       ['concatenate_1[1][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 64)  256         ['conv2d_14[1][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 64, 64, 64)   36928       ['batch_normalization_7[1][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 32  8224       ['conv2d_15[1][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 128, 64  0           ['conv2d_transpose_2[1][0]',     \n",
      "                                )                                 'conv2d_5[1][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 128, 128, 32  18464       ['concatenate_2[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 128, 128, 32  128        ['conv2d_16[1][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 128, 128, 32  9248        ['batch_normalization_8[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 16  2064       ['conv2d_17[1][0]']              \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 256, 32  0           ['conv2d_transpose_3[1][0]',     \n",
      "                                )                                 'conv2d_3[1][0]']               \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 256, 16  4624        ['concatenate_3[1][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 256, 256, 16  64         ['conv2d_18[1][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 256, 256, 16  2320        ['batch_normalization_9[1][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 256, 256, 1)  17          ['conv2d_19[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,944,049\n",
      "Trainable params: 1,942,577\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = unet_model(img_height, img_width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98664b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a05d176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model,\n",
    "#    to_file='model.png',\n",
    "#    show_shapes=True, show_dtype=True,\n",
    "#    show_layer_names=True,\n",
    "#    rankdir='TB',\n",
    "#    expand_nested=True,\n",
    "#    dpi=96,\n",
    "#    layer_range=None,\n",
    "#    show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28171a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be3bdd34",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"/home/lewagon/.pyenv/versions/3.8.12/envs/solar/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_3525/1777002939.py\", line 7, in dice_loss  *\n        intersection = K.sum(targets * inputs)\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type uint8 of argument 'x'.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3525/1339716042.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/solar/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.12/envs/solar/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/home/lewagon/.pyenv/versions/3.8.12/envs/solar/lib/python3.8/site-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/tmp/ipykernel_3525/1777002939.py\", line 7, in dice_loss  *\n        intersection = K.sum(targets * inputs)\n\n    TypeError: Input 'y' of 'Mul' Op has type float32 that does not match type uint8 of argument 'x'.\n"
     ]
    }
   ],
   "source": [
    "model.fit(batch_data(train_X, train_y,batch_size), epochs=1, validation_data=batch_data(val_X, val_y,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668e3af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e1f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431486f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
