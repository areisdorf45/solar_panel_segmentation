{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4d7440-7721-4dda-b0c1-8853668b2b21",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08a505d-e185-4447-abb8-9d2fba6bba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model, layers\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate, Activation, Concatenate\n",
    "from tensorflow.keras.metrics import IoU, BinaryIoU\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.backend as K\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87808c-45fb-4456-8d98-ea69ce4874e5",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4a6e3f6-fbc9-4f10-871f-2901d39e8b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "home = os.environ['HOME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "561d085a-f136-4e27-b427-4460e158d579",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X = os.path.join(home,'raw_data/image_slices')\n",
    "path_y = os.path.join(home,'raw_data/mask_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1da0666-312e-4a2c-a6c7-91ee047f73d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d000d156-83bc-4b49-981f-a9d5c0416363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split (path_X, path_y, split_ratio):\n",
    "    X_names = os.listdir(path_X)\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    train_X, val_X = X_path[:int(len(X_path)*split_ratio)], X_path[int(len(X_path)*split_ratio):]\n",
    "    train_y, val_y = y_path[:int(len(y_path)*split_ratio)], y_path[int(len(y_path)*split_ratio):]\n",
    "    return train_X, val_X, train_y, val_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16dde256-6fc2-49cd-ba13-553180cbd3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_val_split (path_X, path_y, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aeddb1e-9902-49bb-83ec-4df58ad75f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_matching_input_labels(X_names, y_names):\n",
    "    for x, y in zip(X_names, y_names):\n",
    "        if os.path.basename(x) != os.path.basename(y):\n",
    "            raise ValueError(f\"X and Y not matching: {x, y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1faf57c2-9e80-49b6-9436-3c8974bae7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8c04b9-c886-4898-ab22-d994e2f64593",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_matching_input_labels(val_X, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed8f340c-d603-4f01-8156-30ef64535ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    image = tf.image.decode_png(image, channels = 3)\n",
    "    mask = tf.image.decode_png(mask, channels = 1) / 255 \n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27bd5188-fe0a-4080-842a-0776ec69d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data (X_path, y_path, batch_size):\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.shuffle(buffer_size = len(X_path), seed = 10).map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd8a4e9-99d8-4820-91f1-4d04524ae627",
   "metadata": {},
   "source": [
    "### Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dccd6a75-528c-45a1-8087-4a857e436584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 13:32:17.444137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.581318: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.583166: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.587356: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-01 13:32:17.589774: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.591595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:17.593294: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:19.040736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:19.042766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:19.044498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-01 13:32:19.047631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "train_dataset = batch_data(train_X, train_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7d8bf7-8b05-4618-86b7-c96eccefdf74",
   "metadata": {},
   "source": [
    "### Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f4b3ee9-b134-407b-99de-59d59aa9a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = batch_data(val_X, val_y, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401aa3a9-a713-49f9-af9d-ba8b55679f42",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f57f275-a169-44c1-a577-49c135c93ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_X_TEST = os.path.join(home,'raw_data/TEST_slices/test_image_slices')\n",
    "# path_y_TEST = os.path.join(home,'raw_data/TEST_slices/test_mask_slices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1264cea-bf4a-4570-a62b-cd67f54a34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data_test (path_X, path_y, batch_size):\n",
    "    X_names = os.listdir(path_X)\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.map(process_path).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a08703db-88a9-47e4-a553-83ac4ea9b6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST_dataset = batch_data_test(path_X_TEST, path_y_TEST, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea696bf-c7b4-4e49-89ba-2d03c8669ced",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f50a6e10-5c32-449a-8231-9c62defaa603",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, (3,3), padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4ecf07b-46e6-4eb8-b81a-6d86db51c102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters) #can be used as skip connection \n",
    "    p = MaxPooling2D((2,2))(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "001fd9da-03a9-4ca4-af47-9b239d406f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip_features, num_filters): #skip features are going to be the x returned from the encoder block\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f7e53c2-e63a-4bcf-b6d1-a80bd02f0eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(targets, inputs, smooth=1e-6):\n",
    "    \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    \n",
    "    intersection = K.sum(targets * inputs)\n",
    "    dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "    return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df641753-57e6-4221-988d-44996beb2308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_sum(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    o = tf.keras.losses.BinaryCrossentropy()(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8ef0801-13bb-41b2-848c-3fd856183794",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(img_height, img_width, channels):\n",
    "    \n",
    "    inputs = Input((img_height, img_width, channels))\n",
    "    inputs = Lambda(lambda x: x / 255)(inputs) #Normalize the pixels by dividing by 255\n",
    "\n",
    "    #Encoder - downscaling (creating features/filter)\n",
    "    skip1, pool1 = encoder_block(inputs, 16)\n",
    "    skip2, pool2 = encoder_block(pool1, 32) \n",
    "    skip3, pool3 = encoder_block(pool2, 64)\n",
    "    skip4, pool4 = encoder_block(pool3, 128) \n",
    "    \n",
    "    #Bottleneck or bridge between encoder and decoder\n",
    "    b1 = conv_block(pool4, 256)\n",
    "    \n",
    "    #Decoder - upscaling (reconstructing the image and giving it precise spatial location)\n",
    "    decoder1 = decoder_block(b1, skip4, 128)\n",
    "    decoder2 = decoder_block(decoder1, skip3, 64)\n",
    "    decoder3 = decoder_block(decoder2, skip2, 32)\n",
    "    decoder4 = decoder_block(decoder3, skip1, 16)\n",
    "    \n",
    "    #Output\n",
    "    outputs = Conv2D(1, (1, 1), padding='same', activation='sigmoid')(decoder4)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    iou = BinaryIoU()\n",
    "    \n",
    "    model.compile(optimizer='adam', loss=loss_sum, metrics=['accuracy', iou])\n",
    "    \n",
    "    #model.summary()\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d0b5984-3721-44ca-8a08-ca8c95fe17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_unet(256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d25d69a8-86cd-4b1a-a3b9-526c9b770360",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = '../tmp/simple_unet/loss_sum_trainingset'\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint(filepath=checkpoint_filepath, save_weights_only=True, monitor='val_loss', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787df192-b4f3-46f6-b1c4-73c7fc9759cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-01 13:32:24.247942: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 523/3845 [===>..........................] - ETA: 8:36 - loss: 0.7240 - accuracy: 0.8867 - binary_io_u: 0.6829"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, validation_data=val_dataset, epochs = 500, callbacks=[es, checkpoint], verbose=1)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m100"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
