{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "276174f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Model\n",
    "import pathlib\n",
    "from tensorflow.keras import Input\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, BatchNormalization, MaxPooling2D, Conv2DTranspose, concatenate, Concatenate\n",
    "from tensorflow.keras.metrics import MeanIoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99cb11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deviding data by batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c28b18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_path(image_path, mask_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    image = tf.image.decode_png(image, channels = 3)\n",
    "    mask = tf.image.decode_png(mask, channels = 1)\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cd97678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data (path_X, path_y, batch_size):\n",
    "    X_names = os.listdir(path_X)\n",
    "    X_path = [f'{path_X}/{file}' for file in X_names]\n",
    "    y_names = os.listdir(path_y)\n",
    "    y_path = [f'{path_y}/{file}' for file in y_names]\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices((X_path, y_path))\n",
    "    return ds_train.map(process_path).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ef58e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(img_height, img_width, channels):\n",
    "\n",
    "    #Input\n",
    "    inputs = Input((img_height, img_width, channels), name=\"input\")\n",
    "    normalisation = Lambda(lambda x: x / 255, name=\"normalisation\")(inputs) #Normalize the pixels by dividing by 255\n",
    "\n",
    "#     #Encoder where we are extracting the features\n",
    "#     convolution0 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name=\"conv2D1tototootototo\")(normalisation)\n",
    "#     convolution0 = BatchNormalization(name=\"batchnorm1\")(convolution0) #other option is to do dropout by batch is faster \n",
    "#     convolution0 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(convolution0)\n",
    "#     pooling0 = MaxPooling2D((2, 2))(convolution0)\n",
    "      \n",
    "    convolution1 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(normalisation)\n",
    "    convolution1 = BatchNormalization()(convolution1) \n",
    "    convolution1 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(convolution1)\n",
    "    pooling1 = MaxPooling2D((2, 2))(convolution1)\n",
    "    \n",
    "    convolution2 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(pooling1)\n",
    "    convolution2 = BatchNormalization()(convolution2)\n",
    "    convolution2 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(convolution2)\n",
    "    pooling2 = MaxPooling2D((2, 2))(convolution2)\n",
    "     \n",
    "    convolution3 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(pooling2)\n",
    "    convolution3 = BatchNormalization()(convolution3)\n",
    "    convolution3 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(convolution3)\n",
    "    pooling3 = MaxPooling2D((2, 2))(convolution3)\n",
    "     \n",
    "    convolution4 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(pooling3)\n",
    "    convolution4 = BatchNormalization()(convolution4)\n",
    "    convolution4 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(convolution4)\n",
    "    pooling4 = MaxPooling2D(pool_size=(2, 2))(convolution4)\n",
    "\n",
    "    #Bottleneck at the base of the U-net \n",
    "    convolution5 = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same')(pooling4)\n",
    "    convolution5 = BatchNormalization()(convolution5)\n",
    "    convolution5 = Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same')(convolution5)\n",
    "    \n",
    "    #Decoder where we are indicating to the model the precise location of the features \n",
    "    transconv6 = Conv2DTranspose(128, kernel_size=(2, 2), strides=(2, 2), padding='same')(convolution5)\n",
    "    transconv6 = Concatenate()([transconv6, convolution4])\n",
    "    convolution6 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(transconv6)\n",
    "    convolution6 = BatchNormalization()(convolution6)\n",
    "    convolution6 = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same')(convolution6)\n",
    "     \n",
    "    transconv7 = Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding='same')(convolution6)\n",
    "    transconv7 = Concatenate()([transconv7, convolution3])\n",
    "    convolution7 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(transconv7)\n",
    "    convolution7 = BatchNormalization()(convolution7)\n",
    "    convolution7 = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(convolution7)\n",
    "     \n",
    "    transconv8 = Conv2DTranspose(32, kernel_size=(2, 2), strides=(2, 2), padding='same')(convolution7)\n",
    "    transconv8 = Concatenate()([transconv8, convolution2])\n",
    "    convolution8 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(transconv8)\n",
    "    convolution8 = BatchNormalization()(convolution8)\n",
    "    convolution8 = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same')(convolution8)\n",
    "     \n",
    "    transconv9 = Conv2DTranspose(16, kernel_size=(2, 2), strides=(2, 2), padding='same')(convolution8)\n",
    "    transconv9 = Concatenate()([transconv9, convolution1])\n",
    "    convolution9 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(transconv9)\n",
    "    convolution9 = BatchNormalization()(convolution9)\n",
    "    convolution9 = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same')(convolution9)\n",
    "  \n",
    "   \n",
    "    \n",
    "    outputs = Conv2D(1, kernel_size=(1, 1), activation='sigmoid')(convolution9)\n",
    "     \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    jaccard = MeanIoU(2)\n",
    "    \n",
    "    #loss options include: binary_crossentropy, IoU Loss (Jaccard Index), dice loss\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=\"accuracy\") \n",
    "    \n",
    "#     model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3377c44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels=3\n",
    "img_height = 256\n",
    "img_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdaa3458",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(img_height, img_width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba61ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_X = '/home/zhlj/code/solar_panel_segmentation/tests/Small_dataset/Images'\n",
    "path_y = '/home/zhlj/code/solar_panel_segmentation/tests/Small_dataset/Target'\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1edcd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir = \"logs\" , histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3bdd34",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 21:34:06.554661: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8700\n",
      "2022-11-30 21:34:08.914673: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-11-30 21:34:11.370896: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.28GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-11-30 21:34:13.627589: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276/276 [==============================] - 126s 404ms/step - loss: -10680.3926 - accuracy: 0.1935\n",
      "Epoch 2/100\n",
      "276/276 [==============================] - 106s 385ms/step - loss: -98568.5859 - accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "276/276 [==============================] - 104s 377ms/step - loss: -366432.5938 - accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "276/276 [==============================] - 107s 387ms/step - loss: -898590.5000 - accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "276/276 [==============================] - 107s 388ms/step - loss: -1773448.0000 - accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "276/276 [==============================] - 107s 387ms/step - loss: -3043322.2500 - accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "276/276 [==============================] - 106s 386ms/step - loss: -4751603.0000 - accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "276/276 [==============================] - 107s 388ms/step - loss: -6899042.5000 - accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "276/276 [==============================] - 104s 379ms/step - loss: -9558710.0000 - accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "276/276 [==============================] - 105s 377ms/step - loss: -12810749.0000 - accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "276/276 [==============================] - 106s 384ms/step - loss: -16576428.0000 - accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "276/276 [==============================] - 106s 385ms/step - loss: -20910954.0000 - accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "276/276 [==============================] - 104s 378ms/step - loss: -25769102.0000 - accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "276/276 [==============================] - 106s 379ms/step - loss: -31345274.0000 - accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "276/276 [==============================] - 106s 383ms/step - loss: -37707884.0000 - accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "276/276 [==============================] - 107s 388ms/step - loss: -44489948.0000 - accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "276/276 [==============================] - 104s 377ms/step - loss: -52140648.0000 - accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "276/276 [==============================] - 106s 378ms/step - loss: -60371140.0000 - accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "276/276 [==============================] - 105s 383ms/step - loss: -69284232.0000 - accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "276/276 [==============================] - 104s 377ms/step - loss: -78752472.0000 - accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "276/276 [==============================] - 105s 377ms/step - loss: -88533312.0000 - accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "276/276 [==============================] - 105s 383ms/step - loss: -100234720.0000 - accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "276/276 [==============================] - 106s 384ms/step - loss: -112285448.0000 - accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "276/276 [==============================] - 104s 378ms/step - loss: -125398800.0000 - accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "276/276 [==============================] - 105s 383ms/step - loss: -139247088.0000 - accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "276/276 [==============================] - 106s 384ms/step - loss: -152095056.0000 - accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "276/276 [==============================] - 104s 377ms/step - loss: -167215776.0000 - accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "276/276 [==============================] - 105s 383ms/step - loss: -184054432.0000 - accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "236/276 [========================>.....] - ETA: 15s - loss: -198785776.0000 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "history = model.fit(batch_data(path_X,path_y,batch_size), epochs=100, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed096fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f2f90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be02fd1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(image).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf641082",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(image, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4840910",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.cast(image, 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dad044",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75df4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = model.layers[1]\n",
    "output1(tf.cast(image, 'float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd278e",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = [layer.name for layer in model.layers]\n",
    "layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4709dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "layer_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a96363",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f35a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs[1:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c7c3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_map_model(tf.cast(image, 'float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[1].weights[0][:,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[2].weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
